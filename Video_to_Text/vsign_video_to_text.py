# -*- coding: utf-8 -*-
"""VSign Video_to_text

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11iIPrnK86qcW4-xllqVhZ8xnVoMvvgJS

# This notebook takes a video link as input, converts the video into an audio using yt-dlp, then uses OpenAI's Whisper to generate accurate transcripts.
"""

!pip install yt-dlp

!pip install -U openai-whisper

"""# Convert the video into an audio"""

import yt_dlp

url = "https://youtu.be/G6de8L7cVvM?si=jvSZx0r2JL7S4I-o"

ydl_opts = {
    'format': 'bestaudio/best',
    'extractaudio': True,
    'outtmpl': 'audio.%(ext)s',
    'postprocessors': [{
        'key': 'FFmpegExtractAudio',
        'preferredcodec': 'mp3',
        'preferredquality': '192',
    }],
}

with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    ydl.download([url])

audio_path = "/content/audio.mp3"

"""# Convert the audio into a text/transcript"""

import os
import whisper

# Check if the audio file exists
if not os.path.exists(audio_path):
    print(f"Error: Audio file not found at {audio_path}")
    print("Please ensure you've downloaded the audio correctly and set the 'audio_path' variable to the right location.")
else:
    print(f"Audio file found at: {audio_path}")

    # Load the Whisper model
    #print("Loading Whisper model (this may take a moment the first time)...")
    model = whisper.load_model("base") # You can change "base" to "small", "medium", etc.

    # Transcribe the audio
    print(f"Transcribing audio from {audio_path}...")
    result = model.transcribe(audio_path)

    # Print the full transcript
    transcript_text = result["text"]
    print("\n--- Full Transcription ---")
    print(transcript_text)

    # Save the transcript to a text file
    output_transcript_path = "/content/transcript.txt"

    with open(output_transcript_path, "w") as f:
        f.write(transcript_text)
    print(f"\nTranscript saved to: {output_transcript_path}")